
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Xiantao Hu</title>
    <base href="https://xiantaohu.github.io/index">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Xiantao Hu (胡现韬)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="#Education">Education & Experience</a></div>
    
    <div class="menu-item"><a href="#publications">Publications</a></div>
    <div class="menu-item"><a href="#service">Academic Services</a></div>
    <div class="menu-item"><a href="#award">Honors and Awards</a></div>
</td>

<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="center">
        <td><img src="me.jpg" width = '165', height='185' alt="Xiantao Hu" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Xiantao Hu</b></span></p>
            <p>
               Ph.D. Student
            </p>
            <p>
	      Pattern Computing and Application Laboratory (PCA Lab), Nanjing University of Science and Technology (NJUST), China.
	    </p>
            <p>
                [<a href="https://scholar.google.com.hk/citations?user=ZlUB72cAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>]
	    </p>
            <p>
		E-mail:  xiantaohu@njust.edu.cn, huxiantao481@gmail.com  &nbsp; 
            </p>
        </td>
    </tr></table>

    <!-- <p><font color="#FF0000">I am seeking for <b>Assistant Professor</b> or <b>Research Scientist</b>!</font></p> -->

<div>
        <h2><hr><a name="interest"></a>Research Interests</h2>
        <ul>
            <li><p>Visual object tracking</p></li>
            <li><p>Visual Multimodal</p></li>
	    <!-- <li><p>Dataset Condensation</p></li>
	    <li><p>Few-Shot Learning</p></li> -->
        </ul>
 </div>
	
 <div>
        <h2 id='news'><hr><a name="news"></a>News</h2>
        <ul>
	    <li><p> Dec. 2024: One paper was accepted by AAAI 2025.
	    <!-- <li><p> Jul. 2024: One paper was accepted by Pattern Recognition.   -->
        </ul>
 </div>
	
 <div>	
        <h2 id='Education'><hr><a name="Education"></a>Education & Experience</h2>
	
       <ul>

	       <li><p>
                Intern. May 2025 -- Present<br>
                China Mobile Research Institute.<br>
		Advised by Song Wu.
            </p></li>
	       
	    <li><p>
                Ph.D. Septembe 2024 -- Present<br>
                PCA Lab, School of Computer Science and Technology, Nanjing University of Science and Technology (NJUST).<br>
		Advised by Prof. <b> <a href="https://scholar.google.com.hk/citations?user=6CIDtZQAAAAJ&hl=zh-CN" target="_blank"> Jian Yang</a></b> and Associate Prof. <b> <a href="https://scholar.google.com.hk/citations?user=NKaiUasAAAAJ&hl=zh-CN" target="_blank">Ying Tai</a></b>.<br>
            </p></li>
            <li><p>
                M.E. September 2021 -- June 2024<br>
                School of Computer Science and Technology, Guangxi Normal University (GXNU).<br>
		Advised by Prof. <b><a href="https://scholar.google.de/citations?user=hvRBydsAAAAJ&hl=en" target="_blank"> Bineng Zhong </a></b>.<br>
            </p></li>
	    <li><p>
            B.E. September 2017 -- June 2021<br>
                School of Computer Science and Technology, Guangxi Normal University (GXNU).<br>
            </p></li>
        </ul>
    </div>

<!--
 <div>
        <h2><hr><a name="award"></a>Honors and Awards</h2>
        <ul>
            <li><p><b>Excellent Doctoral Dissertation Award</b>, Chinese Institute of Electronics (CIE), China, 2023.</p></li>
            <li><p><b>RIKEN BAIHO Award</b> (a.k.a. RIKEN Excellent Achievement Award,  Annual Selection Rate < 1%), RIKEN National Science Institute, Japan, 2022.</p></li>
            <li><p><b>Excellent Doctoral Dissertation Nomination</b>, Chinese Association for Artificial Intelligence (CAAI), China, 2021.</p></li>
            <li><p><b>Excellent Doctoral Dissertation Award</b> (Annual Selection Rate < 2%), Jiangsu Province, China, 2021.</p></li>
            <li><p><b>National Scholarship</b> (Two Times, Annual Selection Rate < 2%), Ministry of Education, China, 2018 and 2019.</p></li>
            <li><p><b>Top 1% GPA Ranking</b>, School of Computer Science & Engineering, NJUST, China, 2014 -- 2019.</p></li>
            <li><p>The 17th Mathematical Modeling Contest for Chinese Graduate Students, <b>Honorable Mention</b>, Ministry of Education, China, 2015.</p></li>
            <li><p>The 2nd  China Fuzzy Image Processing Contest, <b>Honorable Mention</b>, National Natural Science Foundation, China, 2015.</p></li>
            <li><p>The 34th Mathematical Modeling Contest for American College Students, <b>Honorable Mention</b>, SIAM, USA, 2013.</p></li>
            <li><p>The 2nd Software Programming Contest for Chinese College Students, <b>Meritorious Winner</b>, Ministry of Industry and Information Technology, China, 2012.</p></li>
        </ul>
 </div>
-->

 <div>
        <h2 id='publications'><hr><a name="publications"></a>Publications</h2> 
	<p> <span style="font-size: 100%"> <strong>Conference Papers</strong> (* indicates contributed equally, # indicates corresponding authors)</p>
        <ol>    
	<li><p>Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking.  <a href="https://arxiv.org/abs/2412.15691">[Paper]</a>  <a href="https://github.com/NJU-PCALab/STTrack">[Code]</a> <br>  
              <b><u>Xiantao Hu</u></b>, Ying Tai#, Xu Zhao, Chen Zhao, Zhenyu Zhang, Jun Li, Bineng Zhong, Jian Yang#.<br>
             <i>AAAI Conference on Artificial Intelligence (AAAI), Oral, 2025.</i>
        </ol>
	
	 <p> <span style="font-size: 100%"> <strong>Journal Papers</strong> (* indicates contributed equally, # indicates corresponding authors)</p>
        <ol>


		<li><p>Adaptive Perception for Unified Visual Multi-modal Object Tracking.<br>
                <b><u>Xiantao Hu</u></b>, Bineng Zhong#, Qihua Liang, Liangtao Shi, Zhiyi Mo, Ying Tai, Jian Yang.<br>
             <i>IEEE Transactions on Artificial Intelligence (TAI), 2025.</i>
				    
	     <li><p>Mamba Adapter: Efficient Multi-Modal Fusion for Vision-Language Tracking.<br>
               Liangtao Shi, Bineng Zhong, Qihua Liang,  Xiantao Hu, Zhiyi Mo, Shuxiang Song.<br>
             <i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2025.</i>
		     
		    <li><p>SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding.<br>
               Liangtao Shi, Ting Liu, Xiantao Hu, Yue Hu, Quanjun Yin, Richang Hong.<br>
             <i>IEEE IEEE Transactions on Multimedia (TMM), 2025.</i>
			    
	     <li><p>Towards Modalities Correlation for RGB-T Tracking.<br>
              <b><u>Xiantao Hu</u></b>, Bineng Zhong#, Qihua Liang, Shengping Zhang, Ning Li, Xianxian Li.<br>
             <i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024.</i>
			
	     <li><p>Transformer Tracking via Frequency Fusion.<br>
            <b><u>Xiantao Hu</u></b>, Bineng Zhong#, Qihua Liang, Shengping Zhang, Ning Li, Xianxian Li, Rongrong Ji.<br>
            <i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023.</i>
        </ol>
</div> 
	<div>
            <h2 id='service'><hr><a name="service"></a>Academic Services</h2>
	    <!--
	     <h3>Conference Area Chair</h3>
            <ul>
	        <li><p>Neural Information Processing Systems (NeurIPS), 2022--2024</p></li>
	        <li><p>International Conference on Machine Learning (ICML), 2023--2025</p></li>
		<li><p>International Conference on Learning Representations (ICLR), 2024--2025</p></li>
		<li><p>European Conference on Computer Vision (ECCV), 2024</p></li>
		 <li><p>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR), 2025</p></li>
		 <li><p>AAAI Conference on Artificial Intelligence (AAAI), 2024--2025</p></li>
            </ul>
	    -->
		
            Conference Reviewer
            <ul> 
		<li><p>Winter Conference on Applications of Computer Vision (WACV)</p></li>
		<li><p>International Joint Conference on Artificial Intelligence (IJCAI)</p></li>
            </ul>

	    Journal Reviewer
	    <ul>
                <li><p>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</p></li>
		<li><p>IEEE Transactions on Multimedia (TMM)</p></li>

            </ul>

	   <!--
	    <h3>Workshop Organizer / Program Chair</h3>
            <ul>
                <li><p>International Workshop on Weakly Supervised Learning, 2023</p></li>
            </ul>
	   -->
    </div>
    <div>
        <h2 id='award'><hr><a name="award"></a>Honors and Awards</h2> 
        <ul>
            <li>11/2024 – Third in ICPR 2024 Multi-Modal Visual Pattern Recognition Challenge – Action Recognition Track, and get "Best Research paper"</li>
            <li>12/2023 – Third in 2023 Yangtze River Delta (Wuhu) Artificial Intelligence Competition -  Non motorized vehicle recognition without helmet based on object detection</li>
            <li>10/2023 – National Graduate Scholarship</li>
            <li>08/2023 – Thrid in IFlytek Developer Competition – Stable Diffusion Identification Challenge </li>
            <li>07/2023 – Second in ICCV2023 Workshop challenge – VisDrone2023 </li>
            <li>06/2023 – Second in CVPR2023 AVA Accessibility Vision and Autonomy Challenge – Segmentation Track </li>
            <li>06/2023 – Thrid in CVPR2023 AVA Accessibility Vision and Autonomy Challenge – Keypoint Track </li>
            <li>05/2023 – Third in FGVC10 Workshop at CVPR – PlantTraits2023</li>
            <li>07/2022 – First in ECV2022 - Outdoor Billboard Recognition</li>
            </ul>

    </div>

<!-- <script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script> -->
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>

</html>

